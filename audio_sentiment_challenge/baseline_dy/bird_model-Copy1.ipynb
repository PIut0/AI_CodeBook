{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c1c95c7-5c2c-43c2-98d7-f6b7389fd012",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mk8574/.conda/envs/mk8574_3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import ast\n",
    "import random\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import torchaudio\n",
    "import IPython.display as ipd\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b170b79-e673-4e3f-af8f-d3053afc86ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class config:\n",
    "    seed = 42\n",
    "    num_fold = 1\n",
    "    sample_rate = 16000\n",
    "    n_fft = 1024\n",
    "    hop_length = 512\n",
    "    n_mels = 64\n",
    "    duration = 5\n",
    "    num_classes = 6\n",
    "    train_batch_size = 16\n",
    "    valid_batch_size = 16\n",
    "    model_name = 'swin_v2_s'\n",
    "    epochs = 50\n",
    "    device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "    learning_rate = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "540ab98b-6096-42c6-bb30-baa32bf8905f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_everything(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73209b21-8585-42f0-a80c-13753ae4cf67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_0000</td>\n",
       "      <td>./train/TRAIN_0000.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_0001</td>\n",
       "      <td>./train/TRAIN_0001.wav</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_0002</td>\n",
       "      <td>./train/TRAIN_0002.wav</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_0003</td>\n",
       "      <td>./train/TRAIN_0003.wav</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_0004</td>\n",
       "      <td>./train/TRAIN_0004.wav</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                    path  label\n",
       "0  TRAIN_0000  ./train/TRAIN_0000.wav      1\n",
       "1  TRAIN_0001  ./train/TRAIN_0001.wav      2\n",
       "2  TRAIN_0002  ./train/TRAIN_0002.wav      4\n",
       "3  TRAIN_0003  ./train/TRAIN_0003.wav      5\n",
       "4  TRAIN_0004  ./train/TRAIN_0004.wav      4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/scratch/network/mk8574/audio_sentiment_challenge/data/train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d772e41-91aa-4563-b2c8-083c6fc88ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 41642])\n",
      "16000\n"
     ]
    }
   ],
   "source": [
    "signal, sr = torchaudio.load('/scratch/network/mk8574/audio_sentiment_challenge/data/train/TRAIN_0001.wav')\n",
    "print(signal.shape)\n",
    "print(sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36b966ec-624b-4cf6-a7c3-d05834458b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import augly.audio as audaugs\n",
    "import augly.utils as utils\n",
    "\n",
    "aug = audaugs.Compose([\n",
    "    audaugs.AddBackgroundNoise(p = 0.1),\n",
    "    audaugs.Clip(duration_factor = 0.7),\n",
    "#    audaugs.TimeStretch(rate = 3.0),\n",
    "#    audaugs.Speed(factor = 3.0),\n",
    "    audaugs.Harmonic(p = 0.5),\n",
    "    audaugs.InvertChannels(),\n",
    "    audaugs.OneOf([audaugs.Clicks(p = 0.6),\n",
    "                   audaugs.InsertInBackground(offset_factor = 0.25, p = 0.6)\n",
    "                   ])\n",
    "#    audaugs.ToMono()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50d57e7a-d8e8-4179-b725-f65d2c9527e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from augly.audio.utils import validate_and_load_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2644c35e-575f-4925-9a3c-1fa575f08ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioSentDataset(Dataset):\n",
    "    def __init__(self, df, transformation, target_sample_rate, duration, mode):\n",
    "        self.audio_paths = df['path'].values\n",
    "        if mode in [\"train\",\"valid\"]:\n",
    "            self.labels = df['label'].values\n",
    "        self.transformation = transformation # transformation\n",
    "        self.target_sample_rate = target_sample_rate # sample rate\n",
    "        self.num_samples = target_sample_rate * duration\n",
    "        self.mode = mode # ['train', 'valid', 'test']\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.audio_paths)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        audio_path = os.path.join('/scratch/network/mk8574/audio_sentiment_challenge/data', self.audio_paths[index])\n",
    "\n",
    "        signal, sr = torchaudio.load(audio_path) # loaded the audio\n",
    "        print(signal.shape)\n",
    "        print(signal)\n",
    "        #signal, sr = validate_and_load_audio(audio_path)\n",
    "        \n",
    "        # Now we first checked if the sample rate is same as TARGET_SAMPLE_RATE and if it not equal we perform resampling\n",
    "        if sr != self.target_sample_rate:\n",
    "            resampler = torchaudio.transforms.Resample(sr, self.target_sample_rate)\n",
    "            signal = resampler(signal)\n",
    "       \n",
    "        # IN CASE DATA IS STEREO:\n",
    "        # Next we check the number of channels of the signal\n",
    "        #signal -> (num_channels, num_samples) - Eg.-(2, 14000) -> (1, 14000)\n",
    "        # if signal.shape[0]>1:\n",
    "        #     signalnu = torch.mean(signal, axis=0, keepdim=True)\n",
    "        \n",
    "        \n",
    "        # Lastly we check the number of samples of the signal\n",
    "        #signal -> (num_channels, num_samples) - Eg.-(1, 14000) -> (1, self.num_samples)\n",
    "        # If it is more than the required number of samples, we truncate the signal\n",
    "        if signal.shape[0] > self.num_samples:\n",
    "            signal = signal[:, :self.num_samples]\n",
    "        \n",
    "        # If it is less than the required number of samples, we pad the signal\n",
    "        if signal.shape[0]<self.num_samples:\n",
    "            num_missing_samples = self.num_samples - signal.shape[0]\n",
    "            last_dim_padding = (0, num_missing_samples)\n",
    "            signal = F.pad(signal, last_dim_padding)\n",
    "        \n",
    "        print(signal.shape)\n",
    "        print(signal)\n",
    "        # Finally all the process has been done and now we will extract mel spectrogram from the signal\n",
    "        mel = self.transformation(signal)\n",
    "        \n",
    "        # For pretrained models, we need 3 channel image, so for that we concatenate the extracted mel\n",
    "        image = torch.cat([mel, mel, mel])\n",
    "        print(image.shape)\n",
    "        print(image)\n",
    "        # Normalize the image\n",
    "        max_val = torch.abs(image).max()\n",
    "        \n",
    "        image = image / max_val\n",
    "        \n",
    "        \n",
    "        \n",
    "        if self.mode in ['train', 'valid']:\n",
    "            label = torch.tensor(self.labels[index])\n",
    "            return image, label\n",
    "        \n",
    "        else:\n",
    "            return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f30696b-3abf-4af3-9a72-108ee10ca846",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "mel_spectrogram = torchaudio.transforms.MelSpectrogram(sample_rate=config.sample_rate, \n",
    "                                                      n_fft=config.n_fft, \n",
    "                                                      hop_length=config.hop_length, \n",
    "                                                      n_mels=config.n_mels)\n",
    "# Function to get data according to the folds\n",
    "def get_data():\n",
    "    df = pd.read_csv('/scratch/network/mk8574/audio_sentiment_challenge/data/train.csv')\n",
    "    train_df, valid_df = train_test_split(df, test_size = 0.2, shuffle = True)\n",
    "    \n",
    "    train_dataset = AudioSentDataset(train_df, mel_spectrogram, config.sample_rate, config.duration, mode = 'train')\n",
    "    valid_dataset = AudioSentDataset(valid_df, mel_spectrogram, config.sample_rate, config.duration, mode = 'valid')\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=config.train_batch_size, shuffle=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=config.valid_batch_size, shuffle=True)\n",
    "    \n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e829ddd-2eb1-47d5-b84f-2616a9a97b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdCLEFResnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BirdCLEFResnet, self).__init__()\n",
    "        self.base_model = models.__getattribute__(config.model_name)(pretrained=True)\n",
    "        \n",
    "        #self.base_model = torchaudio.models.hubert_pretrain_base(num_classes=6) \n",
    "        #for param in self.base_model.parameters():\n",
    "            #param.requires_grad = False\n",
    "            \n",
    "        #in_features = self.base_model.head.out_features\n",
    "        \n",
    "        #self.base_model.head.out_features = nn.Linear(1028, config.num_classes)\n",
    "\n",
    "    def forward(self, x,labels):\n",
    "        x = self.base_model(x,labels)\n",
    "        return x, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3edb71-2741-4644-9440-f3e3a49c6e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BirdCLEFResnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85dc3074-6099-423b-a910-b8fe143f45ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(outputs, labels):\n",
    "    SMOOTH = 1e-10\n",
    "    \n",
    "    return nn.CrossEntropyLoss(label_smoothing = 0.3)(outputs + SMOOTH, labels)\n",
    "\n",
    "def train(model, data_loader, optimizer, scheduler, device, epoch):\n",
    "    model.train()\n",
    "    \n",
    "    running_loss = 0\n",
    "    loop = tqdm(data_loader, position=0)\n",
    "    for i, (mels, labels) in enumerate(loop):\n",
    "        mels = mels.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(mels)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        loss = loss_fn(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "        \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "            \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        loop.set_description(f\"Epoch [{epoch+1}/{config.epochs}]\")\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    return running_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fac948-973b-46e9-bee2-ab939953ecea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0d0379a-e5ad-4ad7-a7c1-c02b0e20a0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(model, data_loader, device, epoch):\n",
    "    model.eval()\n",
    "    \n",
    "    running_loss = 0\n",
    "    pred = []\n",
    "    label = []\n",
    "    \n",
    "    loop = tqdm(data_loader, position=0)\n",
    "    for mels, labels in loop:\n",
    "        mels = mels.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(mels)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        loss = loss_fn(outputs, labels)\n",
    "        # print('Outputs:', outputs)\n",
    "        # print('Labels:', labels)\n",
    "            \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        pred.extend(preds.view(-1).cpu().detach().numpy())\n",
    "        label.extend(labels.view(-1).cpu().detach().numpy())\n",
    "        \n",
    "        loop.set_description(f\"Epoch [{epoch+1}/{config.epochs}]\")\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "        \n",
    "    valid_f1 = f1_score(label, pred, average='macro')\n",
    "    label = torch.Tensor(label)\n",
    "    pred = torch.Tensor(pred)\n",
    "    valid_acc = (label == pred).float().sum() / label.shape[0]\n",
    "    \n",
    "    return running_loss/len(data_loader), valid_f1, valid_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "582ef36d-fcd6-4a19-a6da-1bce27c90524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "a = torch.Tensor([1, 2, 3])\n",
    "b = torch.Tensor([1, 4, 5])\n",
    "\n",
    "print((a == b).float().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "443435f9-324c-4171-9205-2479ee004d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    train_loader, valid_loader = get_data()\n",
    "    \n",
    "    model = BirdCLEFResnet().to(config.device)\n",
    "    \n",
    "    optimizer = Adam(model.parameters(), lr=config.learning_rate)\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, eta_min=1e-5, T_max=10)\n",
    "    \n",
    "    best_valid_f1 = 0\n",
    "    for epoch in range(config.epochs):\n",
    "        train_loss = train(model, train_loader, optimizer, scheduler, config.device, epoch)\n",
    "        valid_loss, valid_f1, valid_acc = valid(model, valid_loader, config.device, epoch)\n",
    "        \n",
    "        print(f\"Validation F1 - {valid_f1}, Accuracy - {valid_acc}\")\n",
    "        torch.save(model.state_dict(), f'./model.bin')\n",
    "        print(f\"Saved model checkpoint at ./model.bin\")\n",
    "\n",
    "    return best_valid_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4722e5b2-feb3-4f6d-ac85-e286d3c233bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 43243])\n",
      "tensor([[ 4.5776e-04, -9.1553e-05,  7.6294e-04,  ..., -6.1035e-05,\n",
      "         -6.1035e-05, -6.1035e-05]])\n",
      "torch.Size([1, 123242])\n",
      "tensor([[ 4.5776e-04, -9.1553e-05,  7.6294e-04,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]])\n",
      "torch.Size([3, 64, 241])\n",
      "tensor([[[1.2571e+00, 4.1716e-01, 1.8110e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [2.0988e-01, 1.5240e-01, 4.9530e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [7.6845e-02, 5.8866e-02, 1.2230e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         ...,\n",
      "         [1.3475e-03, 9.8692e-04, 1.2609e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.7765e-03, 1.1456e-03, 1.1753e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [2.9335e-03, 1.3153e-03, 1.1494e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[1.2571e+00, 4.1716e-01, 1.8110e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [2.0988e-01, 1.5240e-01, 4.9530e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [7.6845e-02, 5.8866e-02, 1.2230e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         ...,\n",
      "         [1.3475e-03, 9.8692e-04, 1.2609e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.7765e-03, 1.1456e-03, 1.1753e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [2.9335e-03, 1.3153e-03, 1.1494e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[1.2571e+00, 4.1716e-01, 1.8110e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [2.0988e-01, 1.5240e-01, 4.9530e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [7.6845e-02, 5.8866e-02, 1.2230e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         ...,\n",
      "         [1.3475e-03, 9.8692e-04, 1.2609e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.7765e-03, 1.1456e-03, 1.1753e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [2.9335e-03, 1.3153e-03, 1.1494e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]]])\n",
      "torch.Size([1, 48048])\n",
      "tensor([[-0.0033, -0.0033, -0.0029,  ...,  0.0000,  0.0000,  0.0000]])\n",
      "torch.Size([1, 128047])\n",
      "tensor([[-0.0033, -0.0033, -0.0029,  ...,  0.0000,  0.0000,  0.0000]])\n",
      "torch.Size([3, 64, 251])\n",
      "tensor([[[3.8741e-02, 5.7171e-02, 6.9521e-02,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [6.8955e-03, 1.9953e-01, 9.1719e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [6.2445e-02, 4.7374e-01, 1.4364e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         ...,\n",
      "         [3.8846e-04, 3.7597e-04, 4.6214e-04,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [3.5963e-04, 3.6450e-04, 2.7618e-04,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [3.5335e-04, 2.5993e-04, 3.0193e-04,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[3.8741e-02, 5.7171e-02, 6.9521e-02,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [6.8955e-03, 1.9953e-01, 9.1719e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [6.2445e-02, 4.7374e-01, 1.4364e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         ...,\n",
      "         [3.8846e-04, 3.7597e-04, 4.6214e-04,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [3.5963e-04, 3.6450e-04, 2.7618e-04,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [3.5335e-04, 2.5993e-04, 3.0193e-04,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[3.8741e-02, 5.7171e-02, 6.9521e-02,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [6.8955e-03, 1.9953e-01, 9.1719e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [6.2445e-02, 4.7374e-01, 1.4364e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         ...,\n",
      "         [3.8846e-04, 3.7597e-04, 4.6214e-04,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [3.5963e-04, 3.6450e-04, 2.7618e-04,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [3.5335e-04, 2.5993e-04, 3.0193e-04,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]]])\n",
      "torch.Size([1, 42709])\n",
      "tensor([[-0.0067, -0.0060, -0.0056,  ...,  0.0000,  0.0000,  0.0000]])\n",
      "torch.Size([1, 122708])\n",
      "tensor([[-0.0067, -0.0060, -0.0056,  ...,  0.0000,  0.0000,  0.0000]])\n",
      "torch.Size([3, 64, 240])\n",
      "tensor([[[0.1242, 0.2531, 0.4566,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.1495, 0.3935, 0.2787,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0656, 0.4226, 0.5573,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0013, 0.0020, 0.0013,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0008, 0.0014, 0.0011,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0014, 0.0015, 0.0008,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.1242, 0.2531, 0.4566,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.1495, 0.3935, 0.2787,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0656, 0.4226, 0.5573,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0013, 0.0020, 0.0013,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0008, 0.0014, 0.0011,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0014, 0.0015, 0.0008,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.1242, 0.2531, 0.4566,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.1495, 0.3935, 0.2787,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0656, 0.4226, 0.5573,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0013, 0.0020, 0.0013,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0008, 0.0014, 0.0011,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0014, 0.0015, 0.0008,  ..., 0.0000, 0.0000, 0.0000]]])\n",
      "torch.Size([1, 37371])\n",
      "tensor([[-0.0017, -0.0026, -0.0021,  ..., -0.0003, -0.0003,  0.0000]])\n",
      "torch.Size([1, 117370])\n",
      "tensor([[-0.0017, -0.0026, -0.0021,  ...,  0.0000,  0.0000,  0.0000]])\n",
      "torch.Size([3, 64, 230])\n",
      "tensor([[[2.0348e-01, 1.8989e-01, 5.7147e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.6871e-01, 5.3572e-01, 6.7949e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [2.5766e-01, 5.3542e-01, 5.4221e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         ...,\n",
      "         [1.3533e-03, 8.7721e-04, 5.4560e-04,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [2.3019e-03, 1.4049e-03, 7.1821e-04,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.2682e-03, 1.1291e-03, 1.4067e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[2.0348e-01, 1.8989e-01, 5.7147e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.6871e-01, 5.3572e-01, 6.7949e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [2.5766e-01, 5.3542e-01, 5.4221e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         ...,\n",
      "         [1.3533e-03, 8.7721e-04, 5.4560e-04,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [2.3019e-03, 1.4049e-03, 7.1821e-04,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.2682e-03, 1.1291e-03, 1.4067e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[2.0348e-01, 1.8989e-01, 5.7147e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.6871e-01, 5.3572e-01, 6.7949e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [2.5766e-01, 5.3542e-01, 5.4221e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         ...,\n",
      "         [1.3533e-03, 8.7721e-04, 5.4560e-04,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [2.3019e-03, 1.4049e-03, 7.1821e-04,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.2682e-03, 1.1291e-03, 1.4067e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]]])\n",
      "torch.Size([1, 41642])\n",
      "tensor([[-0.0043, -0.0046, -0.0044,  ...,  0.0000,  0.0000,  0.0000]])\n",
      "torch.Size([1, 121641])\n",
      "tensor([[-0.0043, -0.0046, -0.0044,  ...,  0.0000,  0.0000,  0.0000]])\n",
      "torch.Size([3, 64, 238])\n",
      "tensor([[[0.0485, 0.1136, 0.0819,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.5904, 0.1991, 0.2214,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.2669, 0.5489, 0.1121,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0008, 0.0010, 0.0016,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0017, 0.0014, 0.0009,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0013, 0.0012, 0.0016,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0485, 0.1136, 0.0819,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.5904, 0.1991, 0.2214,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.2669, 0.5489, 0.1121,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0008, 0.0010, 0.0016,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0017, 0.0014, 0.0009,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0013, 0.0012, 0.0016,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0485, 0.1136, 0.0819,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.5904, 0.1991, 0.2214,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.2669, 0.5489, 0.1121,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0008, 0.0010, 0.0016,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0017, 0.0014, 0.0009,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0013, 0.0012, 0.0016,  ..., 0.0000, 0.0000, 0.0000]]])\n",
      "torch.Size([1, 39506])\n",
      "tensor([[-1.1902e-03, -2.6245e-03, -2.6855e-03,  ...,  3.0518e-05,\n",
      "          0.0000e+00, -6.1035e-05]])\n",
      "torch.Size([1, 119505])\n",
      "tensor([[-0.0012, -0.0026, -0.0027,  ...,  0.0000,  0.0000,  0.0000]])\n",
      "torch.Size([3, 64, 234])\n",
      "tensor([[[7.7897e-01, 7.1840e-01, 6.4168e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [2.1068e+00, 5.0677e-01, 6.2522e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [2.3662e+00, 2.5275e-01, 2.6521e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         ...,\n",
      "         [8.0395e-04, 1.3989e-03, 1.4978e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [7.9419e-04, 8.0974e-04, 1.1721e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.7092e-03, 8.6337e-04, 1.4290e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[7.7897e-01, 7.1840e-01, 6.4168e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [2.1068e+00, 5.0677e-01, 6.2522e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [2.3662e+00, 2.5275e-01, 2.6521e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         ...,\n",
      "         [8.0395e-04, 1.3989e-03, 1.4978e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [7.9419e-04, 8.0974e-04, 1.1721e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.7092e-03, 8.6337e-04, 1.4290e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[7.7897e-01, 7.1840e-01, 6.4168e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [2.1068e+00, 5.0677e-01, 6.2522e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [2.3662e+00, 2.5275e-01, 2.6521e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         ...,\n",
      "         [8.0395e-04, 1.3989e-03, 1.4978e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [7.9419e-04, 8.0974e-04, 1.1721e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.7092e-03, 8.6337e-04, 1.4290e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]]])\n",
      "torch.Size([1, 54454])\n",
      "tensor([[-3.7537e-03, -3.6316e-03, -3.5095e-03,  ...,  9.1553e-05,\n",
      "          3.0518e-05, -9.1553e-05]])\n",
      "torch.Size([1, 134453])\n",
      "tensor([[-0.0038, -0.0036, -0.0035,  ...,  0.0000,  0.0000,  0.0000]])\n",
      "torch.Size([3, 64, 263])\n",
      "tensor([[[0.0873, 0.2137, 0.5169,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0531, 0.2197, 0.2929,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.5258, 0.4394, 0.4472,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0006, 0.0007, 0.0023,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0010, 0.0012, 0.0011,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0009, 0.0010, 0.0014,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0873, 0.2137, 0.5169,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0531, 0.2197, 0.2929,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.5258, 0.4394, 0.4472,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0006, 0.0007, 0.0023,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0010, 0.0012, 0.0011,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0009, 0.0010, 0.0014,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0873, 0.2137, 0.5169,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0531, 0.2197, 0.2929,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.5258, 0.4394, 0.4472,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0006, 0.0007, 0.0023,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0010, 0.0012, 0.0011,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0009, 0.0010, 0.0014,  ..., 0.0000, 0.0000, 0.0000]]])\n",
      "torch.Size([1, 36523])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.Size([1, 116522])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.Size([3, 64, 228])\n",
      "tensor([[[1.9156e-09, 5.8956e-02, 2.3388e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [5.5801e-09, 1.4171e-01, 1.8514e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [6.4902e-09, 4.4808e-01, 4.9128e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         ...,\n",
      "         [1.1045e-07, 9.6055e-04, 7.6006e-04,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [7.2525e-08, 5.3035e-04, 1.0418e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [2.0683e-07, 1.0916e-03, 1.4947e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[1.9156e-09, 5.8956e-02, 2.3388e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [5.5801e-09, 1.4171e-01, 1.8514e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [6.4902e-09, 4.4808e-01, 4.9128e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         ...,\n",
      "         [1.1045e-07, 9.6055e-04, 7.6006e-04,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [7.2525e-08, 5.3035e-04, 1.0418e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [2.0683e-07, 1.0916e-03, 1.4947e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[1.9156e-09, 5.8956e-02, 2.3388e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [5.5801e-09, 1.4171e-01, 1.8514e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [6.4902e-09, 4.4808e-01, 4.9128e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         ...,\n",
      "         [1.1045e-07, 9.6055e-04, 7.6006e-04,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [7.2525e-08, 5.3035e-04, 1.0418e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [2.0683e-07, 1.0916e-03, 1.4947e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]]])\n",
      "torch.Size([1, 49650])\n",
      "tensor([[ 1.8311e-04,  1.1597e-03,  1.4648e-03,  ..., -1.2207e-04,\n",
      "         -3.0518e-05,  0.0000e+00]])\n",
      "torch.Size([1, 129649])\n",
      "tensor([[0.0002, 0.0012, 0.0015,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "torch.Size([3, 64, 254])\n",
      "tensor([[[2.7193e-01, 1.2215e-01, 4.4808e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [6.6000e-01, 5.8590e-02, 1.9182e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [7.8446e-01, 5.4684e-01, 4.5379e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         ...,\n",
      "         [9.5909e-04, 8.7229e-04, 7.1660e-04,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [9.4805e-04, 9.0658e-04, 1.1137e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.9110e-03, 7.7952e-04, 9.7021e-04,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[2.7193e-01, 1.2215e-01, 4.4808e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [6.6000e-01, 5.8590e-02, 1.9182e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [7.8446e-01, 5.4684e-01, 4.5379e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         ...,\n",
      "         [9.5909e-04, 8.7229e-04, 7.1660e-04,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [9.4805e-04, 9.0658e-04, 1.1137e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.9110e-03, 7.7952e-04, 9.7021e-04,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[2.7193e-01, 1.2215e-01, 4.4808e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [6.6000e-01, 5.8590e-02, 1.9182e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [7.8446e-01, 5.4684e-01, 4.5379e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         ...,\n",
      "         [9.5909e-04, 8.7229e-04, 7.1660e-04,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [9.4805e-04, 9.0658e-04, 1.1137e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.9110e-03, 7.7952e-04, 9.7021e-04,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]]])\n",
      "torch.Size([1, 44845])\n",
      "tensor([[-2.6855e-03, -2.3193e-03, -2.1362e-03,  ..., -3.0518e-05,\n",
      "         -1.2207e-04, -9.1553e-05]])\n",
      "torch.Size([1, 124844])\n",
      "tensor([[-0.0027, -0.0023, -0.0021,  ...,  0.0000,  0.0000,  0.0000]])\n",
      "torch.Size([3, 64, 244])\n",
      "tensor([[[0.1899, 0.3661, 0.1937,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.1225, 0.2824, 0.3805,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0868, 0.6504, 0.6547,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0010, 0.0013, 0.0012,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0017, 0.0014, 0.0016,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0010, 0.0010, 0.0008,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.1899, 0.3661, 0.1937,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.1225, 0.2824, 0.3805,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0868, 0.6504, 0.6547,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0010, 0.0013, 0.0012,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0017, 0.0014, 0.0016,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0010, 0.0010, 0.0008,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.1899, 0.3661, 0.1937,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.1225, 0.2824, 0.3805,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0868, 0.6504, 0.6547,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0010, 0.0013, 0.0012,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0017, 0.0014, 0.0016,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0010, 0.0010, 0.0008,  ..., 0.0000, 0.0000, 0.0000]]])\n",
      "torch.Size([1, 45912])\n",
      "tensor([[ 0.0129,  0.0122,  0.0114,  ..., -0.0005, -0.0005, -0.0005]])\n",
      "torch.Size([1, 125911])\n",
      "tensor([[0.0129, 0.0122, 0.0114,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "torch.Size([3, 64, 246])\n",
      "tensor([[[8.1217e-01, 9.1636e-02, 1.7391e-02,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [2.9651e-01, 1.1340e-01, 3.5600e-02,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [5.7774e-01, 4.1445e-01, 1.0129e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         ...,\n",
      "         [1.1698e-03, 5.8778e-04, 1.0709e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [7.5921e-04, 1.0986e-03, 9.3301e-04,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [7.9127e-04, 1.6153e-03, 1.2262e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[8.1217e-01, 9.1636e-02, 1.7391e-02,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [2.9651e-01, 1.1340e-01, 3.5600e-02,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [5.7774e-01, 4.1445e-01, 1.0129e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         ...,\n",
      "         [1.1698e-03, 5.8778e-04, 1.0709e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [7.5921e-04, 1.0986e-03, 9.3301e-04,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [7.9127e-04, 1.6153e-03, 1.2262e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[8.1217e-01, 9.1636e-02, 1.7391e-02,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [2.9651e-01, 1.1340e-01, 3.5600e-02,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [5.7774e-01, 4.1445e-01, 1.0129e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         ...,\n",
      "         [1.1698e-03, 5.8778e-04, 1.0709e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [7.5921e-04, 1.0986e-03, 9.3301e-04,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [7.9127e-04, 1.6153e-03, 1.2262e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]]])\n",
      "torch.Size([1, 39506])\n",
      "tensor([[-0.0042, -0.0040, -0.0042,  ...,  0.0000,  0.0000,  0.0000]])\n",
      "torch.Size([1, 119505])\n",
      "tensor([[-0.0042, -0.0040, -0.0042,  ...,  0.0000,  0.0000,  0.0000]])\n",
      "torch.Size([3, 64, 234])\n",
      "tensor([[[0.1301, 0.1491, 0.4793,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.1076, 0.4340, 0.3355,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0518, 0.6488, 0.6523,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0013, 0.0011, 0.0022,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0011, 0.0014, 0.0018,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0007, 0.0008, 0.0018,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.1301, 0.1491, 0.4793,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.1076, 0.4340, 0.3355,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0518, 0.6488, 0.6523,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0013, 0.0011, 0.0022,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0011, 0.0014, 0.0018,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0007, 0.0008, 0.0018,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.1301, 0.1491, 0.4793,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.1076, 0.4340, 0.3355,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0518, 0.6488, 0.6523,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0013, 0.0011, 0.0022,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0011, 0.0014, 0.0018,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0007, 0.0008, 0.0018,  ..., 0.0000, 0.0000, 0.0000]]])\n",
      "torch.Size([1, 30964])\n",
      "tensor([[ 6.7749e-03,  6.5918e-03,  6.0120e-03,  ..., -6.1035e-05,\n",
      "         -1.2207e-04, -1.8311e-04]])\n",
      "torch.Size([1, 110963])\n",
      "tensor([[0.0068, 0.0066, 0.0060,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "torch.Size([3, 64, 217])\n",
      "tensor([[[0.3468, 0.1694, 0.3081,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.1356, 0.1795, 0.0562,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0267, 0.2169, 0.2879,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0010, 0.0014, 0.0010,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0005, 0.0015, 0.0019,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0006, 0.0016, 0.0011,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.3468, 0.1694, 0.3081,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.1356, 0.1795, 0.0562,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0267, 0.2169, 0.2879,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0010, 0.0014, 0.0010,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0005, 0.0015, 0.0019,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0006, 0.0016, 0.0011,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.3468, 0.1694, 0.3081,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.1356, 0.1795, 0.0562,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0267, 0.2169, 0.2879,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0010, 0.0014, 0.0010,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0005, 0.0015, 0.0019,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0006, 0.0016, 0.0011,  ..., 0.0000, 0.0000, 0.0000]]])\n",
      "torch.Size([1, 37371])\n",
      "tensor([[-0.0066, -0.0057, -0.0061,  ...,  0.0002,  0.0002,  0.0000]])\n",
      "torch.Size([1, 117370])\n",
      "tensor([[-0.0066, -0.0057, -0.0061,  ...,  0.0000,  0.0000,  0.0000]])\n",
      "torch.Size([3, 64, 230])\n",
      "tensor([[[9.3791e-01, 5.2299e-01, 8.4793e-02,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [9.5751e-01, 2.1635e-01, 1.0066e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [8.0429e-01, 1.5793e-01, 2.1021e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         ...,\n",
      "         [2.1910e-03, 1.1614e-03, 1.0695e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.6273e-03, 1.3334e-03, 1.6107e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.8984e-03, 9.9145e-04, 7.5633e-04,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[9.3791e-01, 5.2299e-01, 8.4793e-02,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [9.5751e-01, 2.1635e-01, 1.0066e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [8.0429e-01, 1.5793e-01, 2.1021e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         ...,\n",
      "         [2.1910e-03, 1.1614e-03, 1.0695e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.6273e-03, 1.3334e-03, 1.6107e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.8984e-03, 9.9145e-04, 7.5633e-04,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[9.3791e-01, 5.2299e-01, 8.4793e-02,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [9.5751e-01, 2.1635e-01, 1.0066e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [8.0429e-01, 1.5793e-01, 2.1021e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         ...,\n",
      "         [2.1910e-03, 1.1614e-03, 1.0695e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.6273e-03, 1.3334e-03, 1.6107e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.8984e-03, 9.9145e-04, 7.5633e-04,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]]])\n",
      "torch.Size([1, 37904])\n",
      "tensor([[0.0039, 0.0031, 0.0039,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "torch.Size([1, 117903])\n",
      "tensor([[0.0039, 0.0031, 0.0039,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "torch.Size([3, 64, 231])\n",
      "tensor([[[1.4609e-01, 4.9089e-01, 7.7420e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.0176e+00, 2.1049e-01, 7.7166e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [9.7243e-01, 4.9198e-01, 1.3048e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         ...,\n",
      "         [5.0469e-04, 9.3992e-04, 1.1047e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [2.1930e-03, 9.7977e-04, 1.4904e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.7490e-03, 1.3374e-03, 1.9918e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[1.4609e-01, 4.9089e-01, 7.7420e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.0176e+00, 2.1049e-01, 7.7166e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [9.7243e-01, 4.9198e-01, 1.3048e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         ...,\n",
      "         [5.0469e-04, 9.3992e-04, 1.1047e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [2.1930e-03, 9.7977e-04, 1.4904e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.7490e-03, 1.3374e-03, 1.9918e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[1.4609e-01, 4.9089e-01, 7.7420e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.0176e+00, 2.1049e-01, 7.7166e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [9.7243e-01, 4.9198e-01, 1.3048e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         ...,\n",
      "         [5.0469e-04, 9.3992e-04, 1.1047e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [2.1930e-03, 9.7977e-04, 1.4904e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.7490e-03, 1.3374e-03, 1.9918e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]]])\n",
      "torch.Size([1, 41642])\n",
      "tensor([[0.0067, 0.0083, 0.0082,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "torch.Size([1, 121641])\n",
      "tensor([[0.0067, 0.0083, 0.0082,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "torch.Size([3, 64, 238])\n",
      "tensor([[[3.7638e-01, 4.2203e-01, 4.8707e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [3.1688e-01, 3.6256e-02, 1.8582e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [3.1586e-01, 1.4048e-01, 1.0740e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         ...,\n",
      "         [8.9893e-04, 1.5938e-03, 9.9724e-04,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [2.2550e-03, 9.1372e-04, 1.2724e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.8405e-03, 8.5620e-04, 1.6875e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[3.7638e-01, 4.2203e-01, 4.8707e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [3.1688e-01, 3.6256e-02, 1.8582e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [3.1586e-01, 1.4048e-01, 1.0740e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         ...,\n",
      "         [8.9893e-04, 1.5938e-03, 9.9724e-04,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [2.2550e-03, 9.1372e-04, 1.2724e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.8405e-03, 8.5620e-04, 1.6875e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[3.7638e-01, 4.2203e-01, 4.8707e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [3.1688e-01, 3.6256e-02, 1.8582e-01,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [3.1586e-01, 1.4048e-01, 1.0740e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         ...,\n",
      "         [8.9893e-04, 1.5938e-03, 9.9724e-04,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [2.2550e-03, 9.1372e-04, 1.2724e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.8405e-03, 8.5620e-04, 1.6875e-03,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [3, 64, 241] at entry 0 and [3, 64, 251] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m autograd\n\u001b[1;32m      2\u001b[0m autograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 12\u001b[0m, in \u001b[0;36mrun\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m best_valid_f1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config\u001b[38;5;241m.\u001b[39mepochs):\n\u001b[0;32m---> 12\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     valid_loss, valid_f1, valid_acc \u001b[38;5;241m=\u001b[39m valid(model, valid_loader, config\u001b[38;5;241m.\u001b[39mdevice, epoch)\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation F1 - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalid_f1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Accuracy - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalid_acc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[12], line 11\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, data_loader, optimizer, scheduler, device, epoch)\u001b[0m\n\u001b[1;32m      9\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     10\u001b[0m loop \u001b[38;5;241m=\u001b[39m tqdm(data_loader, position\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (mels, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(loop):\n\u001b[1;32m     12\u001b[0m     mels \u001b[38;5;241m=\u001b[39m mels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     13\u001b[0m     labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/.conda/envs/mk8574_3.10/lib/python3.10/site-packages/tqdm/std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1182\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/mk8574_3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.conda/envs/mk8574_3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.conda/envs/mk8574_3.10/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/mk8574_3.10/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    205\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;124;03m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/mk8574_3.10/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:142\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    139\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/mk8574_3.10/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:142\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    139\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/mk8574_3.10/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:119\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m--> 119\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m    122\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[0;32m~/.conda/envs/mk8574_3.10/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:162\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    160\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    161\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[0;32m--> 162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [3, 64, 241] at entry 0 and [3, 64, 251] at entry 1"
     ]
    }
   ],
   "source": [
    "from torch import autograd\n",
    "autograd.set_detect_anomaly(True)\n",
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b54b22-ebe0-4e50-914a-3a2c80614acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc = torchaudio.transforms.MFCC(sample_rate = config.sample_rate,\n",
    "                                 n_mfcc = 20,\n",
    "                                 log_mels = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88218a3-5d72-4d58-a124-39575cd8832f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict():\n",
    "    PATH = \"/scratch/network/mk8574/audio_sentiment_challenge/baseline_dy/model_20231122015145.bin\"\n",
    "    \n",
    "    test_df = pd.read_csv('../data/test.csv')\n",
    "    \n",
    "    \n",
    "    model = BirdCLEFResnet().to(config.device)\n",
    "    \n",
    "    model.load_state_dict(torch.load(PATH))\n",
    "    \n",
    "    test_dataset = AudioSentDataset(test_df, mfcc, config.sample_rate, config.duration, mode = 'test')\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32,shuffle=False)\n",
    "    \n",
    "    \n",
    "    test_df = test_df.drop(['path'], axis = 1)\n",
    "    ans = []\n",
    "    for i, mels in enumerate(tqdm(test_loader, position=0)):   \n",
    "        mels = mels.to(config.device)\n",
    "\n",
    "        mels = torch.argmax(model(mels), dim = 1)\n",
    "        \n",
    "        ans.append(mels)\n",
    "    print(ans)\n",
    "    z = [y.item() for x in ans for y in x]\n",
    "\n",
    "    test_df['label'] = z\n",
    "    test_df.to_csv('submission.csv', index = False)\n",
    "    \n",
    "    print(test_df)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c38d76-c621-4de5-a2f0-1a9f126b124b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8e125d-d803-40ef-b134-c45da7e685fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44183b3f-e49e-474b-935d-d071b145aa7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a6bf3f-5f54-4a50-a5ef-7ebc915f881c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb482e3-deac-4b9f-aac6-79a261c8987d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd33ae7b-3003-45fd-8618-7f30b81fb9f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mk8574_3.10 [~/.conda/envs/mk8574_3.10/]",
   "language": "python",
   "name": "conda_mk8574_3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
