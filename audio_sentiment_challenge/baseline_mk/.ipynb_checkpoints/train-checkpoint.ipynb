{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9081c53e-7e99-4909-9007-919f7072be20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "from dataclasses import asdict, dataclass\n",
    "from typing import Any, Dict, Tuple\n",
    "\n",
    "from datetime import datetime\n",
    "import audiomentations\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from datasets import Dataset\n",
    "from prettytable import PrettyTable\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics import MetricCollection\n",
    "from torchmetrics.classification import MulticlassAccuracy, MulticlassF1Score, MulticlassPrecision, MulticlassRecall\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoFeatureExtractor, AutoModelForAudioClassification\n",
    "from transformers.feature_extraction_utils import BatchFeature\n",
    "\n",
    "transformers.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d31d224-cb01-4d9d-84c5-8b980bfd53c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    # data args\n",
    "    train_csv: str = \"/scratch/network/mk8574/audio_sentiment_challenge/data/train.csv\"\n",
    "    test_csv: str = \"/scratch/network/mk8574/audio_sentiment_challenge/data/test.csv\"\n",
    "\n",
    "    # model args\n",
    "    pretrained_name: str = \"jonatasgrosman/wav2vec2-large-xlsr-53-english\"\n",
    "    \n",
    "    train_serial = datetime.now().strftime(\"%Y%m%d_%H%M%S\") + \"|\" + pretrained_name.replace(\"/\", \"|\")\n",
    "\n",
    "    # k-fold\n",
    "    k_fold_num: int = 0  # if you want to use k-fold validation, set positive integer value.\n",
    "    k_fold_idx: int = 1\n",
    "\n",
    "    # save dir\n",
    "    save_dir: str = f\"/scratch/network/mk8574/audio_sentiment_challenge/baseline_lks/results/{train_serial}/\"\n",
    "\n",
    "    # hparams\n",
    "    seed: int = 42\n",
    "    lr: float = 5e-4\n",
    "    batch_size: int = 10\n",
    "    gradient_accumulate_step: int = 4  # total batch size = batch_size * gradient_accumulate_step\n",
    "    max_epoch: int = batch_size * gradient_accumulate_step\n",
    "    early_stop_patience = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "137033d4-dfe2-4ec8-bf71-e0edaeb0a92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()\n",
    "\n",
    "if not os.path.exists(config.save_dir):\n",
    "    os.makedirs(config.save_dir)\n",
    "\n",
    "with open(os.path.join(config.save_dir, \"config.json\"), \"w\") as config_file:\n",
    "    json.dump(asdict(config), config_file, indent=4, sort_keys=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1eb4a6b5-7304-4e34-905e-e05029bf27e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = config.seed\n",
    "\n",
    "random.seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "# torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf9e314c-eb16-468e-a766-908835546e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained(pretrained_name: str) -> Tuple[AutoModelForAudioClassification, AutoFeatureExtractor]:\n",
    "    # model\n",
    "    model = AutoModelForAudioClassification.from_pretrained(pretrained_name)\n",
    "\n",
    "    model.config.num_labels = 6\n",
    "    model.classifier = nn.Linear(in_features=model.projector.out_features, out_features=6)\n",
    "    nn.init.kaiming_normal_(model.classifier.weight, mode=\"fan_in\", nonlinearity=\"relu\")\n",
    "    nn.init.zeros_(model.classifier.bias)\n",
    "\n",
    "    # feature extractor\n",
    "    feature_extractor = AutoFeatureExtractor.from_pretrained(pretrained_name)\n",
    "\n",
    "    return model, feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7482947c-706b-4498-bf5d-d24321311732",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModule:\n",
    "    def __init__(\n",
    "        self,\n",
    "        feature_extractor: AutoFeatureExtractor,\n",
    "        transforms: list = None,\n",
    "    ):\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def to_dataset(self, df: pd.DataFrame) -> Dataset:\n",
    "        def load_waveform(row):\n",
    "            waveform, sample_rate = librosa.load(row[\"path\"])\n",
    "            waveform = librosa.resample(\n",
    "                waveform,\n",
    "                orig_sr=sample_rate,\n",
    "                target_sr=self.feature_extractor.sampling_rate,\n",
    "            )\n",
    "            row[\"waveform\"] = waveform\n",
    "\n",
    "            return row\n",
    "\n",
    "        dataset = Dataset.from_pandas(df)\n",
    "        dataset = dataset.map(load_waveform, num_proc=4)\n",
    "        if \"label\" in dataset.column_names:\n",
    "            dataset = dataset.rename_column(\"label\", \"labels\")\n",
    "\n",
    "        return dataset\n",
    "\n",
    "    def apply_transforms(self, dataset: Dataset) -> Dataset:\n",
    "        def apply_transforms(batch):\n",
    "            waveforms = [self.transforms(samples=np.array(waveform, dtype=np.float32), sample_rate=self.feature_extractor.sampling_rate) for waveform in batch[\"waveform\"]]\n",
    "            batch[\"waveform\"] = waveforms\n",
    "\n",
    "            return batch\n",
    "\n",
    "        if self.transforms:\n",
    "            dataset = dataset.with_transform(apply_transforms)\n",
    "\n",
    "        return dataset\n",
    "\n",
    "    def collate_fn(self, batch: list) -> BatchFeature:\n",
    "        if hasattr(self.feature_extractor, \"nb_max_frames\"):\n",
    "            padding = \"max_length\"\n",
    "        else:\n",
    "            padding = \"longest\"\n",
    "\n",
    "        waveforms = [data[\"waveform\"] for data in batch]\n",
    "        model_inputs = self.feature_extractor(\n",
    "            waveforms,\n",
    "            sampling_rate=self.feature_extractor.sampling_rate,\n",
    "            padding=padding,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        if \"labels\" in batch[0]:\n",
    "            labels = [data[\"labels\"] for data in batch]\n",
    "            model_inputs[\"labels\"] = torch.tensor(labels)\n",
    "\n",
    "        return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "906a4036-5651-4944-9b3b-75c7b2c761bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricScore(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        metrics = MetricCollection(\n",
    "            {\n",
    "                \"accuracy\": MulticlassAccuracy(num_classes=6),\n",
    "                \"recall\": MulticlassRecall(num_classes=6),\n",
    "                \"precision\": MulticlassPrecision(num_classes=6),\n",
    "                \"f1\": MulticlassF1Score(num_classes=6),\n",
    "            }\n",
    "        )\n",
    "        self.train_metrics = metrics.clone()\n",
    "        self.valid_metrics = metrics.clone()\n",
    "\n",
    "        self.train_losses = []\n",
    "        self.valid_losses = []\n",
    "\n",
    "    def add_train_metrics(self, logits: torch.Tensor, labels: torch.Tensor):\n",
    "        self.train_metrics.update(logits, labels)\n",
    "\n",
    "    def add_valid_metrics(self, logits: torch.Tensor, labels: torch.Tensor):\n",
    "        self.valid_metrics.update(logits, labels)\n",
    "\n",
    "    def add_train_loss(self, loss: torch.Tensor):\n",
    "        self.train_losses.append(loss.item())\n",
    "\n",
    "    def add_valid_loss(self, loss: torch.Tensor):\n",
    "        self.valid_losses.append(loss.item())\n",
    "\n",
    "    def compute_train(self) -> Dict[str, Any]:\n",
    "        scores = self.train_metrics.compute()\n",
    "        for metric_key, score in scores.items():\n",
    "            if isinstance(score, torch.Tensor):\n",
    "                scores[metric_key] = score.item()\n",
    "        scores.update({\"loss\": np.mean(self.train_losses)})\n",
    "\n",
    "        return scores\n",
    "\n",
    "    def compute_valid(self) -> Dict[str, Any]:\n",
    "        scores = self.valid_metrics.compute()\n",
    "        for metric_key, score in scores.items():\n",
    "            if isinstance(score, torch.Tensor):\n",
    "                scores[metric_key] = score.item()\n",
    "        scores.update({\"loss\": np.mean(self.valid_losses)})\n",
    "\n",
    "        return scores\n",
    "\n",
    "    def reset(self):\n",
    "        self.train_metrics.reset()\n",
    "        self.valid_metrics.reset()\n",
    "\n",
    "        self.train_losses = []\n",
    "        self.valid_losses = []\n",
    "\n",
    "    def print_summary(self, epoch_idx: int):\n",
    "        train_result = self.compute_train()\n",
    "        valid_result = self.compute_valid()\n",
    "\n",
    "        assert list(train_result.keys()) == list(valid_result.keys())\n",
    "\n",
    "        pt = PrettyTable()\n",
    "        pt.field_names = [f\"epoch {epoch_idx}\"] + list(train_result.keys())\n",
    "\n",
    "        train_row = [\"train\"]\n",
    "        for score in train_result.values():\n",
    "            train_row.append(round(score, 3))\n",
    "        pt.add_row(train_row)\n",
    "\n",
    "        valid_row = [\"valid\"]\n",
    "        for score in valid_result.values():\n",
    "            valid_row.append(round(score, 3))\n",
    "        pt.add_row(valid_row)\n",
    "\n",
    "        print(pt, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e26b84ed-7e35-470f-bb8e-2edbe3cc2a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(\n",
    "    model: AutoModelForAudioClassification,\n",
    "    train_loader: DataLoader,\n",
    "    valid_loader: DataLoader,\n",
    "    max_epoch: int = 64,\n",
    "    lr: float = 5e-4,\n",
    "    gradient_accumulate_step: int = 1,\n",
    "    early_stop_patience: int = 5,\n",
    ") -> dict:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = model.to(device)\n",
    "    metric_scores = MetricScore().to(device)\n",
    "\n",
    "    optimizer = AdamW(\n",
    "        [{\"params\": module.parameters(), \"lr\": lr if name == \"classifier\" else lr * 0.1} for name, module in model.named_children()],\n",
    "        weight_decay=0.1,\n",
    "    )\n",
    "    lr_scheduler = ReduceLROnPlateau(optimizer, mode=\"max\", factor=0.5, patience=3)\n",
    "\n",
    "    # run finetune\n",
    "    best_score = 0.0\n",
    "    best_state_dict = None\n",
    "\n",
    "    early_stop_count = 0\n",
    "    for epoch_idx in range(1, max_epoch):\n",
    "        with torch.set_grad_enabled(True), tqdm(total=len(train_loader), desc=f\"[Epoch {epoch_idx}/{max_epoch}] training\", leave=False) as pbar:\n",
    "            model.train()\n",
    "            for step_idx, batch in enumerate(train_loader, 1):\n",
    "                batch = batch.to(device)\n",
    "\n",
    "                output = model(**batch)\n",
    "                loss = output.loss\n",
    "                loss.backward()\n",
    "\n",
    "                if step_idx % gradient_accumulate_step == 0 or step_idx == len(train_loader):\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()            \n",
    "\n",
    "                metric_scores.add_train_loss(loss)\n",
    "                metric_scores.add_train_metrics(output.logits, batch.labels)\n",
    "\n",
    "                pbar.update()\n",
    "                pbar.set_postfix({\"train loss\": loss.item()})\n",
    "\n",
    "        with torch.set_grad_enabled(False), tqdm(total=len(valid_loader), desc=f\"[Epoch {epoch_idx}/{max_epoch}] validation\", leave=False) as pbar:\n",
    "            model.eval()\n",
    "            for batch in valid_loader:\n",
    "                batch = batch.to(device)\n",
    "\n",
    "                output = model(**batch)\n",
    "                loss = output.loss\n",
    "\n",
    "                metric_scores.add_valid_loss(loss)\n",
    "                metric_scores.add_valid_metrics(output.logits, batch.labels)\n",
    "\n",
    "                pbar.update()\n",
    "                pbar.set_postfix({\"valid loss\": loss.item()})\n",
    "\n",
    "        epoch_score = metric_scores.compute_valid()[\"accuracy\"]\n",
    "        metric_scores.print_summary(epoch_idx=epoch_idx)\n",
    "        metric_scores.reset()\n",
    "\n",
    "        lr_scheduler.step(epoch_score)\n",
    "\n",
    "        if epoch_score > best_score:\n",
    "            best_score = epoch_score\n",
    "            best_state_dict = model.state_dict()\n",
    "            early_stop_count = 0\n",
    "        else:\n",
    "            early_stop_count += 1\n",
    "            if early_stop_count == early_stop_patience:\n",
    "                print(\"*** EARLY STOPPED ***\")\n",
    "                break\n",
    "    \n",
    "    return best_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "935953e2-1a60-4fec-b597-f039d23f4129",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def predict(\n",
    "    model: AutoModelForAudioClassification,\n",
    "    feature_extractor: AutoFeatureExtractor,\n",
    "    test_dataset: Dataset,\n",
    "    batch_size: int = 16,\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    predict_logits = {\"id\": []}\n",
    "    predict_logits.update({class_id: [] for class_id in range(6)})\n",
    "\n",
    "    predict_class = {\"id\": [], \"label\": []}\n",
    "\n",
    "    for batch_idx in tqdm(range(0, len(test_dataset), batch_size), desc=\"prediction\"):\n",
    "        bs, bi = batch_idx, batch_idx + batch_size\n",
    "        batch = test_dataset[bs:bi]\n",
    "\n",
    "        if hasattr(feature_extractor, \"nb_max_frames\"):\n",
    "            padding = \"max_length\"\n",
    "        else:\n",
    "            padding = \"longest\"\n",
    "\n",
    "        model_inputs = feature_extractor(\n",
    "            batch[\"waveform\"],\n",
    "            sampling_rate=feature_extractor.sampling_rate,\n",
    "            padding=padding,\n",
    "            return_tensors=\"pt\",\n",
    "        ).to(device)\n",
    "\n",
    "        model_output = model(**model_inputs)\n",
    "\n",
    "        batch_logits = model_output.logits.cpu()\n",
    "        batch_predict = model_output.logits.argmax(dim=-1).cpu()\n",
    "\n",
    "        predict_logits[\"id\"] += batch[\"id\"]\n",
    "        for class_id in range(6):\n",
    "            predict_logits[class_id] += batch_logits[:, class_id].tolist()\n",
    "\n",
    "        predict_class[\"id\"] += batch[\"id\"]\n",
    "        predict_class[\"label\"] += batch_predict.tolist()\n",
    "\n",
    "    predict_logits = pd.DataFrame(predict_logits)\n",
    "    predict_class = pd.DataFrame(predict_class)\n",
    "\n",
    "    return predict_logits, predict_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2dd815c9-fa66-47b7-8a13-9da442eb54dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = audiomentations.OneOf(\n",
    "    [\n",
    "        audiomentations.AddGaussianNoise(p=0.75),\n",
    "        audiomentations.PitchShift(p=0.75),\n",
    "        audiomentations.PeakingFilter(p=0.75),\n",
    "        audiomentations.SevenBandParametricEQ(p=0.75),\n",
    "        audiomentations.BandPassFilter(p=0.75),\n",
    "        audiomentations.BandStopFilter(p=0.75),\n",
    "        audiomentations.AirAbsorption(p=0.75),\n",
    "        audiomentations.ClippingDistortion(p=0.75),\n",
    "        audiomentations.HighPassFilter(p=0.75),\n",
    "        audiomentations.HighShelfFilter(p=0.75),\n",
    "        audiomentations.Limiter(p=0.75),\n",
    "        audiomentations.LowPassFilter(p=0.75),\n",
    "        audiomentations.LowShelfFilter(p=0.75),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62313ec3-49f3-4d78-84a6-105a8b81adc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, feature_extractor = load_pretrained(config.pretrained_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c763b4a7-acc9-4f58-bb80-d77dfc123188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train data and valid data\n",
    "df = pd.read_csv(config.train_csv)\n",
    "df[\"path\"] = df[\"path\"].apply(lambda x: os.path.join(os.path.dirname(config.train_csv), x[2:]))\n",
    "\n",
    "# create test data\n",
    "test_df = pd.read_csv(config.test_csv)\n",
    "test_df[\"path\"] = test_df[\"path\"].apply(lambda x: os.path.join(os.path.dirname(config.test_csv), x[2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a74c4a8e-5314-4a66-bec6-e391656bcc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train data and valid data\n",
    "df = pd.read_csv(config.train_csv)\n",
    "df[\"path\"] = df[\"path\"].apply(lambda x: os.path.join(os.path.dirname(config.train_csv), x[2:]))\n",
    "\n",
    "if config.k_fold_num > 0:\n",
    "    skf = StratifiedKFold(n_splits=config.k_fold_num)\n",
    "    train_indices, valid_indices = list(skf.split(df, df[\"label\"]))[config.k_fold_idx]\n",
    "    train_df, valid_df = df.iloc[train_indices], df.iloc[valid_indices]\n",
    "else:\n",
    "    train_df, valid_df = train_test_split(df, train_size=0.9, stratify=df[\"label\"], random_state=seed)\n",
    "\n",
    "# create test data\n",
    "test_df = pd.read_csv(config.test_csv)\n",
    "test_df[\"path\"] = test_df[\"path\"].apply(lambda x: os.path.join(os.path.dirname(config.test_csv), x[2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20358084-813d-4a50-9a3e-ca9880ae05e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=4): 100%|██████████| 4500/4500 [00:08<00:00, 505.24 examples/s] \n",
      "Map (num_proc=4): 100%|██████████| 501/501 [00:03<00:00, 161.69 examples/s]\n"
     ]
    }
   ],
   "source": [
    "data_module = DataModule(\n",
    "    feature_extractor=feature_extractor,\n",
    "    transforms=transforms,\n",
    ")\n",
    "train_dataset = data_module.apply_transforms(data_module.to_dataset(train_df))\n",
    "valid_dataset = data_module.to_dataset(valid_df)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=data_module.collate_fn,\n",
    ")\n",
    "valid_loader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=data_module.collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade73d61-32f1-4452-8859-f11347b5e5a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-------+-----------+--------+-------+\n",
      "| epoch 1 | accuracy |   f1  | precision | recall |  loss |\n",
      "+---------+----------+-------+-----------+--------+-------+\n",
      "|  train  |  0.458   | 0.451 |   0.462   | 0.458  | 1.365 |\n",
      "|  valid  |  0.661   | 0.642 |   0.679   | 0.661  | 0.888 |\n",
      "+---------+----------+-------+-----------+--------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-------+-----------+--------+-------+\n",
      "| epoch 2 | accuracy |   f1  | precision | recall |  loss |\n",
      "+---------+----------+-------+-----------+--------+-------+\n",
      "|  train  |  0.659   | 0.657 |   0.657   | 0.659  |  0.92 |\n",
      "|  valid  |  0.679   | 0.664 |   0.709   | 0.679  | 0.851 |\n",
      "+---------+----------+-------+-----------+--------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 3/32] training:  95%|█████████▌| 535/563 [03:21<00:10,  2.69it/s, train loss=1.03] "
     ]
    }
   ],
   "source": [
    "best_state_dict = fit(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    valid_loader=valid_loader,\n",
    "    max_epoch=config.max_epoch,\n",
    "    lr=config.lr,\n",
    "    gradient_accumulate_step=config.gradient_accumulate_step,\n",
    "    early_stop_patience=config.early_stop_patience,\n",
    ")\n",
    "\n",
    "model.load_state_dict(best_state_dict)\n",
    "model.save_pretrained(os.path.join(config.save_dir, \"best_model\"))\n",
    "feature_extractor.save_pretrained(os.path.join(config.save_dir, \"best_model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c67ac4-3904-4bd6-9224-e5e749c38f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = data_module.to_dataset(test_df)\n",
    "predict_logits, predict_class = predict(model, feature_extractor, test_dataset, config.batch_size)\n",
    "\n",
    "predict_logits.to_csv(os.path.join(config.save_dir, \"predict_logits.csv\"), index=False)\n",
    "predict_class.to_csv(os.path.join(config.save_dir, \"predict_class.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mk8574_3.10 [~/.conda/envs/mk8574_3.10/]",
   "language": "python",
   "name": "conda_mk8574_3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
